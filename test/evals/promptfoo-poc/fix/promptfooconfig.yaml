# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: "Fixes"

prompts:
  - file://prompt.txt

providers:
  - file://fix.provider.yml

tests:
  - vars:
      preBuildState: file://tests/shared/pre_build.go
      changes: file://tests/removal/changes.md
      problems: file://tests/removal/problems.txt
      postBuildState: file://tests/removal/post_build.go
    assert:
      - type: is-json
      - type: is-valid-openai-tools-call
      - type: javascript
        value: |
          var args = JSON.parse(output[0].function.arguments)
          return (
            args.problems && 
            args.changes.length > 0 &&
            args.changes.some(
              change => change.hasChange && 
                        change.new.includes("var contextRmCmd = &cobra.Command{")
            )
          )
